{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33265f91-515b-41cc-8771-35cf1af5a081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "199dd8c8-387d-4ae0-a916-2801282afa05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\davin\\Desktop\\Python\\ML\\DL\\Image_Matching_2025\\Code\\LightGlue\\lightglue\\lightglue.py:24: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from lightglue import LightGlue, SuperPoint, DISK, SIFT, ALIKED, DoGHardNet\n",
    "from lightglue.utils import load_image, rbd\n",
    "from lightglue import viz2d\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from lightglue import match_pair\n",
    "from itertools import combinations\n",
    "import h5py\n",
    "import numpy as np\n",
    "import re\n",
    "import subprocess\n",
    "import pycolmap\n",
    "from database import COLMAPDatabase\n",
    "from h5_to_db import add_keypoints, add_matches\n",
    "from tqdm import tqdm\n",
    "import kornia.feature as KF\n",
    "import open3d as o3d\n",
    "import global_dino_extractor as gdino\n",
    "import pair_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f68de2c4-c935-435c-8ed4-a56708260db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path): \n",
    "    file_path = os.path.join(os.getcwd(),\"image-matching-challenge-2025\", path)\n",
    "    return pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a130ff1c-cab6-45fe-aa2d-e493190fb673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_image(img_paths, scenes, n_cols=7, figsize=(15, 8)): \n",
    "    n_rows = len(img_paths) // 7 + 1\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, img_path in enumerate(img_paths):\n",
    "        #In case we have more images than subplots\n",
    "        if i >= len(axes): \n",
    "            break\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None: \n",
    "            axes[i].set_title(\"No Image found\")\n",
    "            axes[i].axis(\"off\")\n",
    "            continue\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        axes[i].imshow(img_rgb)\n",
    "        axes[i].axis(\"off\")\n",
    "        axes[i].set_title(f\"{scenes[i]}\")\n",
    "        \n",
    "    for j in range(i+1, len(axes)): \n",
    "        axes[j].axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8ed502a-1d97-4f69-b6ca-429684298677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pair_index(paths): \n",
    "    #Obtains all index pairs of small list\n",
    "    return list(combinations(range(len(paths)), 2))\n",
    "\n",
    "def find_keypoints(extractor, paths, feature_dir): \n",
    "    with h5py.File(feature_dir/ \"keypoints.h5\", mode=\"a\") as f_keypoints, h5py.File(feature_dir / \"descriptors.h5\", mode=\"a\") as f_descriptors: \n",
    "        for path in tqdm(paths, desc=\"Computing and saving keypoints...\"): \n",
    "            #If path is a string and not Path(..) object\n",
    "            if(isinstance(path, str)): \n",
    "                path = Path(path)\n",
    "            key = path.name\n",
    "            if key in f_keypoints and key in f_descriptors: \n",
    "                print(f\"This key {key} is already here\")\n",
    "                continue\n",
    "                \n",
    "            #Using inference_mode to save memory and efficienter\n",
    "            with torch.inference_mode(): \n",
    "                image = load_image(path)\n",
    "                feats = extractor.extract(image)\n",
    "                keypoints = feats[\"keypoints\"]\n",
    "                descriptors = feats[\"descriptors\"]\n",
    "                if not isinstance(keypoints, np.ndarray): \n",
    "                    keypoints = keypoints.squeeze().cpu().numpy()\n",
    "                if not isinstance(descriptors, np.ndarray): \n",
    "                    descriptors = descriptors.squeeze().cpu().numpy() \n",
    "                f_keypoints[key] = keypoints\n",
    "                f_descriptors[key] = descriptors\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8bcb9fe-e864-4308-bddc-896d8350c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_image(f_keypoints, f_descriptors, f_matches, device, key1_path, key2_path, matcher,  show_comparison = False, show_points=False):\n",
    "    min_matches=20\n",
    "    image0 = load_image(key1_path)\n",
    "    image1 = load_image(key2_path)\n",
    "    key1 = Path(key1_path).name\n",
    "    key2 = Path(key2_path).name\n",
    "\n",
    "    feats0 = {\n",
    "        \"keypoints\": torch.from_numpy(f_keypoints[key1][...])[None].to(device), \n",
    "        \"descriptors\": torch.from_numpy(f_descriptors[key1][...])[None].to(device)\n",
    "    }\n",
    "    feats1 = {\n",
    "        \"keypoints\": torch.from_numpy(f_keypoints[key2][...])[None].to(device), \n",
    "        \"descriptors\": torch.from_numpy(f_descriptors[key2][...])[None].to(device)\n",
    "    }\n",
    "    #Match the features\n",
    "    matches01 = matcher({'image0': feats0, 'image1': feats1})\n",
    "    feats0, feats1, matches01 = [rbd(x) for x in [feats0, feats1, matches01]]\n",
    "    matches = matches01['matches'].to(device)\n",
    "    points0 = feats0['keypoints'][matches[..., 0]]\n",
    "    points1 = feats1['keypoints'][matches[..., 1]]\n",
    "    desc0 = feats0['descriptors'][matches[..., 0]]\n",
    "    desc1 = feats1['descriptors'][matches[..., 1]]\n",
    "\n",
    "    # Compute L2 distance between descriptors (to match matcher output style)\n",
    "    descriptor_distances = torch.norm(desc0 - desc1, dim=1)\n",
    "    #descriptor_distances = descriptor_distances.unsqueeze(1)  # from [N] to [N,1]\n",
    "    distance = torch.norm(points0 - points1, dim=1)\n",
    "    if show_comparison: \n",
    "        axes = viz2d.plot_images([image0, image1])\n",
    "        viz2d.plot_matches(points0, points1, color=\"lime\", lw=0.2)\n",
    "        viz2d.add_text(0, f'Stop after {matches01[\"stop\"]} layers', fs=20)\n",
    "        kpc0, kpc1 = viz2d.cm_prune(matches01[\"prune0\"]), viz2d.cm_prune(matches01[\"prune1\"])\n",
    "        viz2d.plot_images([image0, image1])\n",
    "        viz2d.plot_keypoints([feats0[\"keypoints\"], feats1[\"keypoints\"]], colors=[kpc0, kpc1], ps=10)\n",
    "        \n",
    "    n_matches = len(matches)  \n",
    "    if n_matches >= min_matches: \n",
    "        group = f_matches.require_group(key1)\n",
    "\n",
    "        # if key2 in group: \n",
    "        #     print(f\"Skipping {key1} - {key2}, already matched.\")\n",
    "        #     return\n",
    "        # group.create_dataset(key2, data=matches.detach().cpu().numpy().reshape(-1, 2), naxshape=(None, 2))   \n",
    "        \n",
    "        new_data = matches.detach().cpu().numpy().reshape(-1, 2)\n",
    "        \n",
    "        if key2 in group:\n",
    "            ds = group[key2]\n",
    "            old_shape = ds.shape[0]\n",
    "            ds.resize((old_shape + new_data.shape[0], 2))\n",
    "            ds[old_shape:] = new_data\n",
    "        else:\n",
    "            group.create_dataset(\n",
    "                key2,\n",
    "                data=new_data,\n",
    "                maxshape=(None, 2),\n",
    "                chunks=True\n",
    "        )\n",
    "            \n",
    "\n",
    "#Importing h5 file to colmap database\n",
    "def import_into_colmap(path, feature_dir, database_path): \n",
    "    db = COLMAPDatabase.connect(database_path)\n",
    "    db.create_tables()\n",
    "    single_camera = False\n",
    "    fname_to_id = add_keypoints(db, feature_dir, path, \"\", \"simple-pinhole\", single_camera)\n",
    "    add_matches(db, \n",
    "                feature_dir, \n",
    "                fname_to_id)\n",
    "    db.commit()\n",
    "\n",
    "#Reconstruct the 3d image by finding the rotation matrix and translation vector\n",
    "def reconstruct_images(output_path, database_path, images_dir):\n",
    "    mapper_options = pycolmap.IncrementalPipelineOptions()\n",
    "    mapper_options.min_model_size = 3\n",
    "    mapper_options.max_num_models = 2\n",
    "    \n",
    "    maps = pycolmap.incremental_mapping(\n",
    "        database_path=database_path, \n",
    "        image_path=images_dir,\n",
    "        output_path=Path.cwd() / output_path, \n",
    "        options=mapper_options,\n",
    "    )\n",
    "\n",
    "    #Create\n",
    "    data = []\n",
    "    for model in maps.values(): \n",
    "        for image_id, image in model.images.items(): \n",
    "            rotation = image.cam_from_world.rotation.matrix().flatten().tolist()\n",
    "            translation = image.cam_from_world.translation.tolist()\n",
    "            row = [image.name, \";\".join(str(x) for x in rotation) , \";\".join(str(x) for x in translation)]\n",
    "            data.append(row)\n",
    "    \n",
    "    columns = (['image_name'] + ['rotation_matrix'] + ['translation_vector'])\n",
    "    \n",
    "    #Save to CSV\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    file_name = 'camera_poses.csv'\n",
    "    write_header = not os.path.exists(file_name)\n",
    "    \n",
    "    df.to_csv(file_name, mode='a', header=write_header, index=False)\n",
    "    \n",
    "    print(f'Camera poses saved to {file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83b484cd-77ff-4e80-b0ea-47920dbc1575",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To 3d visualize the reconstructed image\n",
    "def visualize_reconstructed(reconstruct_path):  \n",
    "    recon = pycolmap.Reconstruction(reconstruct_path)\n",
    "    points = [point.xyz for point in recon.points3D.values()]\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cb8f66-f0b5-4aa3-ba6c-483525865e6b",
   "metadata": {},
   "source": [
    "Running everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f963054-3ee0-4171-9828-cee37ed13558",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_csv(\"train_labels.csv\")\n",
    "df[\"image_path\"] = df.apply(lambda row: os.path.join(os.getcwd(), \"image-matching-challenge-2025\", \"train\",  row[\"dataset\"], row[\"image\"]), axis=1)\n",
    "device=\"cuda\"\n",
    "output_npz_path = \"./dino_embeddings/train_embeddings_vits.npz\"\n",
    "dino_embedding = \"./dino_embeddings/train_embeddings_vits.npz\"\n",
    "extractor = ALIKED(max_num_keypoints=2048, resize = 1024).eval()\n",
    "feature_dir = Path(os.path.join(os.getcwd() , \"feature_extraction\"))\n",
    "matcher = LightGlue(features=\"aliked\", depth_confidence=1.0, width_confidence=1.0).eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c57a89-a2e5-46bc-b1c2-146c49ac1c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_reconstruction(output_npz_path, \n",
    "                       dino_embedding, \n",
    "                       image_list_csv_path, \n",
    "                       base_image_dir,\n",
    "                       generate_key_des=True, \n",
    "                       extractor=extractor , \n",
    "                       matcher=matcher, \n",
    "                       feature_dir = feature_dir, \n",
    "                       database_path = \"colmap.db\", \n",
    "                       device=\"cuda\"): \n",
    "    \n",
    "    df = read_csv(\"train_labels.csv\")\n",
    "    df[\"image_path\"] = df.apply(lambda row: os.path.join(os.getcwd(), \"image-matching-challenge-2025\", \"train\",  row[\"dataset\"], row[\"image\"]), axis=1)\n",
    "    \n",
    "    if not os.path.exists(dino_embedding):\n",
    "        gdino.extract_features_and_save(\n",
    "            image_list_csv_path=image_list_csv_path, \n",
    "            output_npz_path = output_npz_path, \n",
    "            base_image_dir=base_image_dir\n",
    "        )\n",
    "    data = np.load(dino_embedding)\n",
    "    pairs = pair_selector.select_pairs_by_embedding_similarity(data.files, data)\n",
    "    index_pairs = [(data.files.index(a), data.files.index(b)) for a, b in pairs]\n",
    "\n",
    "    data_dict = {}\n",
    "    for i in range(df.shape[0]): \n",
    "        dataset = df.iloc[i][\"dataset\"]\n",
    "        scene = df.iloc[i][\"scene\"]\n",
    "        path = df.iloc[i][\"image_path\"]\n",
    "        data_dict.setdefault(dataset, {}).setdefault(scene, []).append(path)\n",
    "\n",
    "    datasets = list(data_dict.keys())\n",
    "    \n",
    "    for dataset in datasets: \n",
    "        print(dataset)\n",
    "        for scene in data_dict[dataset]: \n",
    "            images_dir = Path(data_dict[dataset][scene][0]).parent\n",
    "            image_paths = data_dict[dataset][scene]\n",
    "            if generate_key_des:\n",
    "                find_keypoints(extractor, image_paths , feature_dir)\n",
    "        with h5py.File(feature_dir/\"keypoints.h5\", 'r') as f: \n",
    "            print(f.keys())\n",
    "\n",
    "    \n",
    "    file_path = os.path.join(feature_dir, \"matches.h5\")\n",
    "    if os.path.exists(file_path): \n",
    "        os.remove(file_path)\n",
    "        print(\"Old matches.h5 deleted\")\n",
    "        \n",
    "    \n",
    "    data_dict = {}\n",
    "    for i in range(df.shape[0]): \n",
    "        dataset = df.iloc[i][\"dataset\"]\n",
    "        scene = df.iloc[i][\"scene\"]\n",
    "        path = df.iloc[i][\"image_path\"]\n",
    "        data_dict.setdefault(dataset, {}).setdefault(scene, []).append(path)\n",
    "\n",
    "    datasets = list(data_dict.keys())\n",
    "\n",
    "    #Changes needed here\n",
    "    total=0\n",
    "    for dataset in datasets: \n",
    "        print(dataset)\n",
    "        for scene in data_dict[dataset]: \n",
    "            images_dir = Path(data_dict[dataset][scene][0]).parent\n",
    "            image_paths = data_dict[dataset][scene]\n",
    "            print(f\"There're {len(image_paths)} images!\")\n",
    "            print(f\"From Index {total} - {total+len(image_paths)}\")\n",
    "\n",
    "            with h5py.File(feature_dir / \"keypoints.h5\", mode=\"r\") as f_keypoints, h5py.File(feature_dir / \"descriptors.h5\", mode=\"r\") as f_descriptors, h5py.File(feature_dir/\"matches.h5\", mode=\"a\") as f_matches:\n",
    "                path_pair_index = [(a, b) for a, b in index_pairs if total <= a < total+len(image_paths) and total <= b < total+len(image_paths)]\n",
    "                for i1, i2 in tqdm(path_pair_index, desc=\"Computing keypoint distances\"):\n",
    "                    key1, key2 = Path(df[\"image_path\"][i1]), Path(df[\"image_path\"][i2])\n",
    "                    compare_image(f_keypoints, f_descriptors, f_matches, device, key1, key2, matcher, False)\n",
    "                print(list(f_matches.keys()))\n",
    "                \n",
    "            images_dir = Path(image_paths[0]).parent\n",
    "            if os.path.exists(\"colmap.db\"): \n",
    "                os.unlink(\"colmap.db\")\n",
    "                print(\"Old colmap.db is deleted\")\n",
    "            import_into_colmap(images_dir, feature_dir, database_path)\n",
    "            #until here\n",
    "            \n",
    "            pycolmap.match_exhaustive(database_path)\n",
    "            reconstruct_path = os.path.join(os.getcwd(), \"reconstruct_pipeline_outputs\")\n",
    "            reconstruct_images(reconstruct_path, database_path, images_dir)\n",
    "                \n",
    "            total += len(image_paths)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7afd3f-2ddd-4a28-8312-fb70e87ea264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imc2023_haiper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing and saving keypoints...: 100%|████████████████████████████████████████████| 23/23 [00:00<00:00, 11669.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This key fountain_image_116.png is already here\n",
      "This key fountain_image_108.png is already here\n",
      "This key fountain_image_101.png is already here\n",
      "This key fountain_image_082.png is already here\n",
      "This key fountain_image_071.png is already here\n",
      "This key fountain_image_025.png is already here\n",
      "This key fountain_image_000.png is already here\n",
      "This key fountain_image_007.png is already here\n",
      "This key fountain_image_012.png is already here\n",
      "This key fountain_image_033.png is already here\n",
      "This key fountain_image_173.png is already here\n",
      "This key fountain_image_056.png is already here\n",
      "This key fountain_image_186.png is already here\n",
      "This key fountain_image_199.png is already here\n",
      "This key fountain_image_230.png is already here\n",
      "This key fountain_image_214.png is already here\n",
      "This key fountain_image_041.png is already here\n",
      "This key fountain_image_166.png is already here\n",
      "This key fountain_image_163.png is already here\n",
      "This key fountain_image_155.png is already here\n",
      "This key fountain_image_143.png is already here\n",
      "This key fountain_image_136.png is already here\n",
      "This key fountain_image_129.png is already here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing and saving keypoints...: 100%|████████████████████████████████████████████| 15/15 [00:00<00:00, 10260.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This key bike_image_119.png is already here\n",
      "This key bike_image_115.png is already here\n",
      "This key bike_image_038.png is already here\n",
      "This key bike_image_049.png is already here\n",
      "This key bike_image_139.png is already here\n",
      "This key bike_image_029.png is already here\n",
      "This key bike_image_150.png is already here\n",
      "This key bike_image_137.png is already here\n",
      "This key bike_image_004.png is already here\n",
      "This key bike_image_128.png is already here\n",
      "This key bike_image_062.png is already here\n",
      "This key bike_image_076.png is already here\n",
      "This key bike_image_088.png is already here\n",
      "This key bike_image_094.png is already here\n",
      "This key bike_image_101.png is already here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing and saving keypoints...: 100%|███████████████████████████████████████████████| 16/16 [01:18<00:00,  4.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['bike_image_004.png', 'bike_image_029.png', 'bike_image_038.png', 'bike_image_049.png', 'bike_image_062.png', 'bike_image_076.png', 'bike_image_088.png', 'bike_image_094.png', 'bike_image_101.png', 'bike_image_115.png', 'bike_image_119.png', 'bike_image_128.png', 'bike_image_137.png', 'bike_image_139.png', 'bike_image_150.png', 'chairs_image_004.png', 'chairs_image_020.png', 'chairs_image_035.png', 'chairs_image_045.png', 'chairs_image_051.png', 'chairs_image_073.png', 'chairs_image_094.png', 'chairs_image_103.png', 'chairs_image_115.png', 'chairs_image_122.png', 'chairs_image_131.png', 'chairs_image_141.png', 'chairs_image_144.png', 'chairs_image_152.png', 'chairs_image_155.png', 'chairs_image_160.png', 'fountain_image_000.png', 'fountain_image_007.png', 'fountain_image_012.png', 'fountain_image_025.png', 'fountain_image_033.png', 'fountain_image_041.png', 'fountain_image_056.png', 'fountain_image_071.png', 'fountain_image_082.png', 'fountain_image_101.png', 'fountain_image_108.png', 'fountain_image_116.png', 'fountain_image_129.png', 'fountain_image_136.png', 'fountain_image_143.png', 'fountain_image_155.png', 'fountain_image_163.png', 'fountain_image_166.png', 'fountain_image_173.png', 'fountain_image_186.png', 'fountain_image_199.png', 'fountain_image_214.png', 'fountain_image_230.png']>\n",
      "imc2023_heritage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing and saving keypoints...: 100%|███████████████████████████████████████████████| 61/61 [03:38<00:00,  3.59s/it]\n",
      "Computing and saving keypoints...: 100%|███████████████████████████████████████████████| 75/75 [05:08<00:00,  4.12s/it]\n",
      "Computing and saving keypoints...:  93%|███████████████████████████████████████████▊   | 28/30 [04:10<00:18,  9.15s/it]"
     ]
    }
   ],
   "source": [
    "run_reconstruction(output_npz_path, dino_embedding, \"./image-matching-challenge-2025/train_labels.csv\", \"./image-matching-challenge-2025/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31968a27-ebe6-4dae-ad73-5f0ae3c3c5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyENV_NEW",
   "language": "python",
   "name": "myenv_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
